---
title: 读LLM Powered Autonomous Agents了解Agent System

author: Vi_error

description:  了解Agent

categories:

- AI/LLM/Agent

tags:

- [ LLM,Agent ]

---


由于最近在做Agent产品功能和技术设计梳理，需要对AI、Agent的知识有系统性的了解，所以开始重读Agent相关的经典文章，顺便做一些记录。

这篇文章是对LLM Powered Autonomous Agents的学习，LLM Powered Autonomous Agents被认为是Agent系统性论述的起点。

这篇笔记只关注以下内容：

- 为什么需要Agent
- Agent需要解决哪些问题
- Agent System overview

原文中还有各系统component的详细论述，这里不展开，后面技术设计的时候再分析。

## 背景，为什么需要Agent

Lilian Weng的文章LLM Powered Autonomous Agents对于Agent概念有非常重要的作用，这个文章记录了这篇文章的内容整理。

文章发表的时间是2023年，彼时LLM的能力开始展现，虽然LLM上生长出的繁杂产品大多还在推广期，但是基于LLM的能力做一些有价值的尝试已经开始广泛的出现。

文章的开始讲：

> Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples.

加一下中文译文：

> 以 LLM（大型语言模型）作为核心控制器构建代理是一个很酷的概念。AutoGPT、GPT-Engineer 和 BabyAGI 等几个概念验证演示是鼓舞人心的例子。LLM 的潜力不仅限于生成写得很好的副本、故事、论文和程序;它可以被框定为一个强大的一般问题解决者。

人们一直尝试用AI完成一些任务，我很喜欢之前看到的一个描述，LLM是一个能力强大但是不可预测的高手，它可以完成很多工作，但很可能不是以你以为的方式完成，完成的效果也不太合适。Maybe可以把它理解为雍和宫or黄老邪，或者一个能力非常强但是管理服从性很差的下属。为了能让AI发挥更大的价值，需要完成很多工作保证它能够正确使用自己的能力，以预计的方式完成我们想要它完成的工作。

这里还要提到一个问题，因为模型训练是有一定的滞后性，因此模型本身的知识会落后于当前时间，模型也无法感知此次此刻的人类社会发生的事情。比如说各种chatLLM都会支持联网搜索，以便在解决问题的过程中获取到模型本身并不具备的信息。

在这里我们可以第一个知识总结：

*想要更好的应用LLM的能力完成一些更为复杂的任务，不能只依靠模型本身，而需要构建一个工具。*

## Agent System Overview

在Agent System Overview的章节中，描述了Agent系统的核心组成。

- Planning
- Memory
- Tool use

翻译成中文

- 规划
- 记忆
- 工具

在具体的了解这些组件由哪些部分组成之前，可以先考虑下为什么会这样划分。

如果经常使用chatGPT或者其他类型的产品，其实很容易注意到这些部分已经融入到产品中，并且能有效的提升对话效果。

罗列一下我们在使用LLM中遇到的问题：

- 当我们想要做的事情很复杂的时候，LLM无法帮我们完成整个任务，需要我们先规划任务，然后逐个任务步骤寻求解答，最后才能可能解答问题
- LLM无法正确的理解我们的意图，需要不断的调整提问的句子，在更换了若干种问法之后，LLM终于理解或者最终让你放弃
- LLM总是默认使用英文回答你（如果你使用的是chatGPT，这里只是举个例子），直到有天你告诉它，请始终使用中文回答我。然后LLM提示：好的，记忆已更新。后面的对话就不用反复强调请用中文回答我了
- 然后是信息落后，最初chatGPT开放出来的功能是不允许联网搜索的，于是当面临一些比较新的问题的时候，模型会给出几年之前的回答甚至胡乱回答，现在提供了联网搜索功能，LLM可以借助实时的网络搜索查询到最新信息，这也就是借助了外部能力

如果归纳一下上面问题和解决方式，提高模型帮我们处理问题时的表现，那么大概是这样的：

- 针对复杂任务：如果我们能把大的任务拆分成小的任务，保证每个小任务的完成效果，那么就可以获得更好的效果
- 针对沟通中自然语言理解不正确的问题：最好LLM能始终记的我是谁，我们在说什么，有哪些信息（知识）是很重要的，我们已经强调过，如果模型始终能够保持这些记忆，那么聊天的效果也会更好
- 针对模型能力不足：我一定会问到模型不了解或者无法处理的问题，如果这个问题或者模型所需的信息有其他的系统可以提供，那么模型能够使用这些能力的话，就可以处理这个问题

ok，复习一下Agent System Overview中component设计：

![Overview of a LLM-powered autonomous agent system](../posts_image/Overview%20of%20a%20LLM-powered%20autonomous%20agent%20system.png)

> - 规划
>   - 子目标和分解：代理将大型任务分解为较小的、可管理的子目标，从而能够高效处理复杂任务。
>   - 反思和完善：代理人可以对过去的行为进行自我批评和自我反省，从错误中吸取教训并为未来的步骤进行改进，从而提高最终结果的质量。
> - 记忆
>   - 短期记忆：我认为所有的上下文学习（参见提示工程）都是利用模型的短期记忆来学习的。
>   - 长期记忆：这为代理提供了在较长时间内保留和调用（无限）信息的能力，通常是通过利用外部向量存储和快速检索。
> - 工具使用
>   - 代理学习调用外部 API 以获取模型权重中缺少的额外信息（通常在预训练后很难更改），包括当前信息、代码执行能力、对专有信息源的访问等。

到这里基本就能理解What is Agent，当然文章到这里还没结束，接下来是对每个component的详细描述。

这个学习笔记到这里要结束了，接下来的学习内容是，理解想要做好一个Agent，我们需要在每一个component上完成哪些事情。
